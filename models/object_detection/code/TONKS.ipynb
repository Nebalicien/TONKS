{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copie de tensorflow_traffic_sign_detection.ipynb","provenance":[{"file_id":"https://github.com/dctian/DeepPiCar/blob/master/models/object_detection/code/tensorflow_traffic_sign_detection.ipynb","timestamp":1594562234602}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"uQCnYPVDrsgx","colab_type":"text"},"source":["# Training a Raspberry Pi to Detect Traffic Signs and People in Real Time\n","\n","This is tutorial is based on Chengwei's excellent Tutorial and Colab Notebook on [\"How to train an object detection model easy for free\"](https://www.dlology.com/blog/how-to-train-an-object-detection-model-easy-for-free/).   My twist on his tutorial is that I need to run my model on a Raspberry Pi with live video feed.  As the Raspberry Pi is fairly limited on CPU power and can only run object detection at 1-2 FPS (frames/sec), I have purchased the newly release $75 Google's [EdgeTPU USB Accelarator](https://coral.withgoogle.com/products/accelerator), which can detect objects at 12 FPS, which is sufficient for real time work.  After doing the transfer learning from one of the object detection models using our own images, last few steps of the colab deals with how to convert a trained model to a model file that can be consumed by an Edge TPU, namely, the final `mymodel_quantized_edgetpu.tflite` file.  \n","\n","\n","![](https://cdn-images-1.medium.com/max/1000/1*_jABdMfUVcyPdi5b3zlfVg.jpeg)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"etOThFKokSmU","colab_type":"text"},"source":["# Section 1: Mount Google drive\n","Mount my Google Drive and save modeling output files (`.ckpt`)  there, so that it won't be wiped out when colab Virtual Machine restarts.  It has an idle timeout of 90 min, and maximum daily usage of 12 hours.\n","\n","Google will ask for an authenticate code when you run the following code, just follow the link in the output and allow access.   You can put the `model_dir` anywhere in your google drive."]},{"cell_type":"code","metadata":{"id":"fA1y7NMxFT_B","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":89},"executionInfo":{"status":"ok","timestamp":1594562794296,"user_tz":-120,"elapsed":7137,"user":{"displayName":"Clément Nicolas Graffard","photoUrl":"https://lh6.googleusercontent.com/-NkV18IrPyAg/AAAAAAAAAAI/AAAAAAAAH4E/7zBQvWoa2og/s64/photo.jpg","userId":"04495214703013170771"}},"outputId":"b77cfdb4-86a6-43df-a5d2-9050e1cffd75"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","model_dir = '/content/gdrive/My Drive/Colab Notebooks/TransferLearning/Training'\n","#!rm -rf '{model_dir}'\n","#os.makedirs(model_dir, exist_ok=True)\n","!ls -ltra '{model_dir}'/.."],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","total 4\n","drwx------ 5 root root 4096 Jul 11 21:25 Training\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yhzxsJb3dpWq","colab_type":"text"},"source":["# Section 2: Configs and Hyperparameters\n","\n","Support a variety of models, you can find more pretrained model from [Tensorflow detection model zoo: COCO-trained models](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models), as well as their pipline config files in [object_detection/samples/configs/](https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs)."]},{"cell_type":"code","metadata":{"id":"gnNXNQCjdniL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":104},"executionInfo":{"status":"ok","timestamp":1594562794301,"user_tz":-120,"elapsed":7123,"user":{"displayName":"Clément Nicolas Graffard","photoUrl":"https://lh6.googleusercontent.com/-NkV18IrPyAg/AAAAAAAAAAI/AAAAAAAAH4E/7zBQvWoa2og/s64/photo.jpg","userId":"04495214703013170771"}},"outputId":"b2cbd0f6-7b49-4dd3-f3db-6f68c1f0a490"},"source":["%tensorflow_version 1.X\n","\n","# If you forked the repository, you can replace the link.\n","repo_url = 'https://github.com/dctian/DeepPiCar'\n","\n","# Number of training steps.\n","num_steps = 1000  # 200000\n","#num_steps = 100  # 200000\n","\n","# Number of evaluation steps.\n","num_eval_steps = 50\n","\n","\n","# model configs are from Model Zoo github: \n","# https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models\n","MODELS_CONFIG = {\n","    #http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_quantized_300x300_coco14_sync_2018_07_18.tar.gz\n","    'ssd_mobilenet_v1_quantized': {\n","        'model_name': 'ssd_mobilenet_v1_quantized_300x300_coco14_sync_2018_07_18',\n","        'pipeline_file': 'ssd_mobilenet_v1_quantized_300x300_coco14_sync.config',\n","        'batch_size': 12\n","    },    \n","    'ssd_mobilenet_v2': {\n","        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n","        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n","        'batch_size': 12\n","    },\n","    #http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03.tar.gz\n","    'ssd_mobilenet_v2_quantized': {\n","        'model_name': 'ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03',\n","        'pipeline_file': 'ssd_mobilenet_v2_quantized_300x300_coco.config',\n","        'batch_size': 12\n","    },\n","    'faster_rcnn_inception_v2': {\n","        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n","        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n","        'batch_size': 12\n","    },\n","    'rfcn_resnet101': {\n","        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n","        'pipeline_file': 'rfcn_resnet101_pets.config',\n","        'batch_size': 12\n","    }\n","}\n","\n","# Pick the model you want to use\n","# Select a model in `MODELS_CONFIG`.\n","# Note: for Edge TPU, you have to:\n","# 1) start with a pretrained model from model zoo, such as above 4\n","# 2) Must be a quantized model, which reduces the model size significantly\n","selected_model = 'ssd_mobilenet_v1_quantized'\n","\n","# Name of the object detection model to use.\n","MODEL = MODELS_CONFIG[selected_model]['model_name']\n","\n","# Name of the pipline file in tensorflow object detection API.\n","pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n","\n","# Training batch size fits in Colabe's Tesla K80 GPU memory for selected model.\n","batch_size = MODELS_CONFIG[selected_model]['batch_size']"],"execution_count":2,"outputs":[{"output_type":"stream","text":["`%tensorflow_version` only switches the major version: 1.x or 2.x.\n","You set: `1.X`. This will be interpreted as: `1.x`.\n","\n","\n","TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rw-YqZHUKv-Y","colab_type":"text"},"source":["# Section 3: Set up Training Environment"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"3_xVkoa4KjHO"},"source":["## Clone the `DeepPiCar` repository or your fork."]},{"cell_type":"code","metadata":{"id":"dxc3DmvLQF3z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":104},"executionInfo":{"status":"ok","timestamp":1594562798628,"user_tz":-120,"elapsed":11429,"user":{"displayName":"Clément Nicolas Graffard","photoUrl":"https://lh6.googleusercontent.com/-NkV18IrPyAg/AAAAAAAAAAI/AAAAAAAAH4E/7zBQvWoa2og/s64/photo.jpg","userId":"04495214703013170771"}},"outputId":"13e72c11-18ca-4e6b-b5da-61cf2b39e059"},"source":["import os\n","\n","%cd /content\n","\n","repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n","\n","!git clone {repo_url}\n","%cd {repo_dir_path}\n","\n","print('Pull it so that we have the latest code/data')\n","!git pull"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content\n","fatal: destination path 'DeepPiCar' already exists and is not an empty directory.\n","/content/DeepPiCar\n","Pull it so that we have the latest code/data\n","Already up to date.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bI8__uNS8-ns","colab_type":"text"},"source":["## Install required packages"]},{"cell_type":"code","metadata":{"id":"ecpHEnka8Kix","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":139},"executionInfo":{"status":"ok","timestamp":1594562823283,"user_tz":-120,"elapsed":36059,"user":{"displayName":"Clément Nicolas Graffard","photoUrl":"https://lh6.googleusercontent.com/-NkV18IrPyAg/AAAAAAAAAAI/AAAAAAAAH4E/7zBQvWoa2og/s64/photo.jpg","userId":"04495214703013170771"}},"outputId":"43558760-2002-483f-e2ff-73210244775a"},"source":["%cd /content\n","!git clone --quiet https://github.com/tensorflow/models.git\n","\n","!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n","\n","!pip install -q Cython contextlib2 pillow lxml matplotlib\n","\n","!pip install -q pycocotools\n","\n","!pip install tf_slim\n","\n","%cd /content/models/research\n","!protoc object_detection/protos/*.proto --python_out=.\n","\n","import os\n","os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n","\n","!python object_detection/builders/model_builder_test.py"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content\n","fatal: destination path 'models' already exists and is not an empty directory.\n","Requirement already satisfied: tf_slim in /usr/local/lib/python3.6/dist-packages (1.1.0)\n","Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf_slim) (0.9.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py>=0.2.2->tf_slim) (1.12.0)\n","/content/models/research\n","object_detection/protos/input_reader.proto: warning: Import object_detection/protos/image_resizer.proto but not used.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"u-k7uGThXlny","colab_type":"text"},"source":["## Prepare `tfrecord` files\n","\n","Use the following scripts to generate the `tfrecord` files.\n","\n","```"]},{"cell_type":"code","metadata":{"id":"ezGDABRXXhPP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":489},"executionInfo":{"status":"ok","timestamp":1594562837298,"user_tz":-120,"elapsed":50060,"user":{"displayName":"Clément Nicolas Graffard","photoUrl":"https://lh6.googleusercontent.com/-NkV18IrPyAg/AAAAAAAAAAI/AAAAAAAAH4E/7zBQvWoa2og/s64/photo.jpg","userId":"04495214703013170771"}},"outputId":"ebde81a2-52a9-4a66-ba1b-09b5a7ecd7fc"},"source":["%cd {repo_dir_path}/models/object_detection\n","\n","# Convert train folder annotation xml files to a single csv file,\n","# generate the `label_map.pbtxt` file to `data/` directory as well.\n","!python code/xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv -l data/annotations\n","\n","# Convert test folder annotation xml files to a single csv.\n","!python code/xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\n","\n","# Generate `train.record`\n","!python code/generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n","\n","# Generate `test.record`\n","!python code/generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/content/DeepPiCar/models/object_detection\n","Successfully converted xml to csv.\n","Generate `data/annotations/label_map.pbtxt`\n","Successfully converted xml to csv.\n","WARNING:tensorflow:From code/generate_tfrecord.py:134: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From code/generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","W0712 14:07:11.196085 139683646506880 module_wrapper.py:139] From code/generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","WARNING:tensorflow:From code/generate_tfrecord.py:53: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0712 14:07:11.240379 139683646506880 module_wrapper.py:139] From code/generate_tfrecord.py:53: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","Successfully created the TFRecords: /content/DeepPiCar/models/object_detection/data/annotations/train.record\n","WARNING:tensorflow:From code/generate_tfrecord.py:134: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From code/generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","W0712 14:07:15.416666 140607597037440 module_wrapper.py:139] From code/generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","WARNING:tensorflow:From code/generate_tfrecord.py:53: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0712 14:07:15.431792 140607597037440 module_wrapper.py:139] From code/generate_tfrecord.py:53: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","Successfully created the TFRecords: /content/DeepPiCar/models/object_detection/data/annotations/test.record\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tgd-fzAIkZlV","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594562837300,"user_tz":-120,"elapsed":50055,"user":{"displayName":"Clément Nicolas Graffard","photoUrl":"https://lh6.googleusercontent.com/-NkV18IrPyAg/AAAAAAAAAAI/AAAAAAAAH4E/7zBQvWoa2og/s64/photo.jpg","userId":"04495214703013170771"}}},"source":["test_record_fname = repo_dir_path + '/models/object_detection/data/annotations/test.record'\n","train_record_fname = repo_dir_path + '/models/object_detection/data/annotations/train.record'\n","label_map_pbtxt_fname = repo_dir_path + '/models/object_detection/data/annotations/label_map.pbtxt'"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"rZ8otnfyCYdG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":625},"executionInfo":{"status":"ok","timestamp":1594562840059,"user_tz":-120,"elapsed":52800,"user":{"displayName":"Clément Nicolas Graffard","photoUrl":"https://lh6.googleusercontent.com/-NkV18IrPyAg/AAAAAAAAAAI/AAAAAAAAH4E/7zBQvWoa2og/s64/photo.jpg","userId":"04495214703013170771"}},"outputId":"c904a7c1-b1a5-44f2-ee6e-3042c22273b4"},"source":["!cat data/annotations/test_labels.csv"],"execution_count":7,"outputs":[{"output_type":"stream","text":["filename,width,height,class,xmin,ymin,xmax,ymax\n","2019-04-16-100738.jpg,640,480,Speed Limit 40,164,128,202,179\n","2019-04-16-100738.jpg,640,480,Person,193,206,217,285\n","2019-04-16-100738.jpg,640,480,Stop Sign,230,134,303,204\n","2019-04-16-100738.jpg,640,480,Speed Limit 25,338,128,383,179\n","2019-04-16-100738.jpg,640,480,Person,418,235,453,335\n","2019-04-16-100738.jpg,640,480,Stop Sign,436,138,469,175\n","2019-04-16-101426.jpg,640,480,Stop Sign,187,138,233,182\n","2019-04-16-101426.jpg,640,480,Green Traffic Light,275,130,330,208\n","2019-04-16-101426.jpg,640,480,Person,362,269,404,397\n","2019-04-16-101426.jpg,640,480,Person,413,211,438,282\n","2019-04-16-101426.jpg,640,480,Speed Limit 25,356,133,393,177\n","2019-04-16-101426.jpg,640,480,Speed Limit 40,429,138,466,187\n","2019-04-16-101426.jpg,640,480,Red Traffic Light,509,137,550,227\n","2019-04-16-095558.jpg,640,480,Speed Limit 25,78,111,153,204\n","2019-04-16-095558.jpg,640,480,Green Traffic Light,223,132,251,184\n","2019-04-16-095558.jpg,640,480,Stop Sign,298,129,361,193\n","2019-04-16-095558.jpg,640,480,Red Traffic Light,393,129,417,182\n","2019-04-16-095558.jpg,640,480,Red Traffic Light,515,133,547,191\n","2019-04-16-101240.jpg,640,480,Stop Sign,38,146,67,173\n","2019-04-16-101240.jpg,640,480,Speed Limit 25,100,139,130,176\n","2019-04-16-101240.jpg,640,480,Person,146,183,164,226\n","2019-04-16-101240.jpg,640,480,Red Traffic Light,174,139,189,175\n","2019-04-16-101240.jpg,640,480,Person,205,179,229,224\n","2019-04-16-101240.jpg,640,480,Green Traffic Light,268,138,288,176\n","2019-04-16-101240.jpg,640,480,Speed Limit 40,303,137,328,169\n","2019-04-16-101240.jpg,640,480,Stop Sign,372,143,404,175\n","2019-04-16-100317.jpg,640,480,Speed Limit 25,3,138,50,201\n","2019-04-16-100317.jpg,640,480,Person,91,206,124,271\n","2019-04-16-100317.jpg,640,480,Stop Sign,121,143,164,185\n","2019-04-16-100317.jpg,640,480,Stop Sign,242,137,282,175\n","2019-04-16-100317.jpg,640,480,Speed Limit 40,313,134,352,185\n","2019-04-16-100317.jpg,640,480,Person,479,206,516,270\n","2019-04-16-100317.jpg,640,480,Green Traffic Light,487,139,508,181\n","2019-04-16-100317.jpg,640,480,Red Traffic Light,597,148,622,192\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iCNYAaC7w6N8","colab_type":"text"},"source":["## Download base model"]},{"cell_type":"code","metadata":{"id":"orDCj6ihgUMR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594562842952,"user_tz":-120,"elapsed":55680,"user":{"displayName":"Clément Nicolas Graffard","photoUrl":"https://lh6.googleusercontent.com/-NkV18IrPyAg/AAAAAAAAAAI/AAAAAAAAH4E/7zBQvWoa2og/s64/photo.jpg","userId":"04495214703013170771"}},"outputId":"e5dc084c-d17d-4e6e-cfc6-60d5f34f9540"},"source":["%cd /content/models/research\n","\n","import os\n","import shutil\n","import glob\n","import urllib.request\n","import tarfile\n","MODEL_FILE = MODEL + '.tar.gz'\n","DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n","DEST_DIR = '/content/models/research/pretrained_model'\n","\n","if not (os.path.exists(MODEL_FILE)):\n","    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n","\n","tar = tarfile.open(MODEL_FILE)\n","tar.extractall()\n","tar.close()\n","\n","os.remove(MODEL_FILE)\n","if (os.path.exists(DEST_DIR)):\n","    shutil.rmtree(DEST_DIR)\n","os.rename(MODEL, DEST_DIR)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["/content/models/research\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pGhvAObeiIix","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":191},"executionInfo":{"status":"ok","timestamp":1594562849590,"user_tz":-120,"elapsed":62304,"user":{"displayName":"Clément Nicolas Graffard","photoUrl":"https://lh6.googleusercontent.com/-NkV18IrPyAg/AAAAAAAAAAI/AAAAAAAAH4E/7zBQvWoa2og/s64/photo.jpg","userId":"04495214703013170771"}},"outputId":"60e76fbc-b61c-41a3-a2a4-b12c8c62ab7d"},"source":["!echo {DEST_DIR}\n","!ls -alh {DEST_DIR}"],"execution_count":9,"outputs":[{"output_type":"stream","text":["/content/models/research/pretrained_model\n","total 130M\n","drwxr-xr-x  2 345018 89939 4.0K Jul 19  2018 .\n","drwxr-xr-x 63 root   root  4.0K Jul 12 14:07 ..\n","-rw-r-----  1 345018 89939  27M Jul 19  2018 model.ckpt.data-00000-of-00001\n","-rw-r-----  1 345018 89939  15K Jul 19  2018 model.ckpt.index\n","-rw-r-----  1 345018 89939 2.2M Jul 19  2018 model.ckpt.meta\n","-rw-r-----  1 345018 89939 4.4K Jul  8  2018 pipeline.config\n","-rw-r--r--  1 345018 89939  27M Jul 18  2018 tflite_graph.pb\n","-rw-r--r--  1 345018 89939  75M Jul 18  2018 tflite_graph.pbtxt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UHnxlfRznPP3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1594562849592,"user_tz":-120,"elapsed":62293,"user":{"displayName":"Clément Nicolas Graffard","photoUrl":"https://lh6.googleusercontent.com/-NkV18IrPyAg/AAAAAAAAAAI/AAAAAAAAH4E/7zBQvWoa2og/s64/photo.jpg","userId":"04495214703013170771"}},"outputId":"baf7c68b-c157-4632-dd5a-f94e0a3467e2"},"source":["fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n","fine_tune_checkpoint"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'/content/models/research/pretrained_model/model.ckpt'"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"aYW8J5JoLP4I","colab_type":"text"},"source":["# Section 4: Transfer Learning Training"]},{"cell_type":"markdown","metadata":{"id":"MvwtHlLOeRJD","colab_type":"text"},"source":["## Configuring a Training Pipeline"]},{"cell_type":"code","metadata":{"id":"dIhw7IdpLuiU","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594562849595,"user_tz":-120,"elapsed":62287,"user":{"displayName":"Clément Nicolas Graffard","photoUrl":"https://lh6.googleusercontent.com/-NkV18IrPyAg/AAAAAAAAAAI/AAAAAAAAH4E/7zBQvWoa2og/s64/photo.jpg","userId":"04495214703013170771"}}},"source":["import os\n","pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n","\n","assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"fG1nCNpUXcRU","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594562849597,"user_tz":-120,"elapsed":62284,"user":{"displayName":"Clément Nicolas Graffard","photoUrl":"https://lh6.googleusercontent.com/-NkV18IrPyAg/AAAAAAAAAAI/AAAAAAAAH4E/7zBQvWoa2og/s64/photo.jpg","userId":"04495214703013170771"}}},"source":["def get_num_classes(pbtxt_fname):\n","    from object_detection.utils import label_map_util\n","    label_map = label_map_util.load_labelmap(pbtxt_fname)\n","    categories = label_map_util.convert_label_map_to_categories(\n","        label_map, max_num_classes=90, use_display_name=True)\n","    category_index = label_map_util.create_category_index(categories)\n","    return len(category_index.keys())"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"YjtCbLF2i0wI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594562850609,"user_tz":-120,"elapsed":63290,"user":{"displayName":"Clément Nicolas Graffard","photoUrl":"https://lh6.googleusercontent.com/-NkV18IrPyAg/AAAAAAAAAAI/AAAAAAAAH4E/7zBQvWoa2og/s64/photo.jpg","userId":"04495214703013170771"}}},"source":["import re\n","\n","# training pipeline file defines:\n","# - pretrain model path\n","# - the train/test sets\n","# - ID to Label mapping and number of classes\n","# - training batch size\n","# - epochs to trains\n","# - learning rate\n","# - etc\n","\n","# note we just need to use a sample one, and make edits to it.\n","\n","num_classes = get_num_classes(label_map_pbtxt_fname)\n","with open(pipeline_fname) as f:\n","    s = f.read()\n","with open(pipeline_fname, 'w') as f:\n","    \n","    # fine_tune_checkpoint: downloaded pre-trained model checkpoint path\n","    s = re.sub('fine_tune_checkpoint: \".*?\"',\n","               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n","    \n","    # tfrecord files train and test, we created earlier with our training/test sets\n","    s = re.sub(\n","        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n","    s = re.sub(\n","        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n","\n","    # label_map_path: ID to label file\n","    s = re.sub(\n","        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n","\n","    # Set training batch_size.\n","    s = re.sub('batch_size: [0-9]+',\n","               'batch_size: {}'.format(batch_size), s)\n","\n","    # Set training steps, num_steps (Number of epochs to train)\n","    s = re.sub('num_steps: [0-9]+',\n","               'num_steps: {}'.format(num_steps), s)\n","    \n","    # Set number of classes num_classes.\n","    s = re.sub('num_classes: [0-9]+',\n","               'num_classes: {}'.format(num_classes), s)\n","    f.write(s)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"0IH96bbydOWn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":521},"executionInfo":{"status":"ok","timestamp":1594562853886,"user_tz":-120,"elapsed":66555,"user":{"displayName":"Clément Nicolas Graffard","photoUrl":"https://lh6.googleusercontent.com/-NkV18IrPyAg/AAAAAAAAAAI/AAAAAAAAH4E/7zBQvWoa2og/s64/photo.jpg","userId":"04495214703013170771"}},"outputId":"6f3e9ccd-a923-4d97-b834-079d383a77ec"},"source":["!cat {label_map_pbtxt_fname}"],"execution_count":14,"outputs":[{"output_type":"stream","text":["item {\n","    id: 1\n","    name: 'Green Traffic Light'\n","}\n","\n","item {\n","    id: 2\n","    name: 'Person'\n","}\n","\n","item {\n","    id: 3\n","    name: 'Red Traffic Light'\n","}\n","\n","item {\n","    id: 4\n","    name: 'Speed Limit 25'\n","}\n","\n","item {\n","    id: 5\n","    name: 'Speed Limit 40'\n","}\n","\n","item {\n","    id: 6\n","    name: 'Stop Sign'\n","}"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GH0MEEanocn6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594562856956,"user_tz":-120,"elapsed":69613,"user":{"displayName":"Clément Nicolas Graffard","photoUrl":"https://lh6.googleusercontent.com/-NkV18IrPyAg/AAAAAAAAAAI/AAAAAAAAH4E/7zBQvWoa2og/s64/photo.jpg","userId":"04495214703013170771"}},"outputId":"e1e9d8cf-c39e-4fa8-b577-ee4a355325e4"},"source":["# look for num_classes: 6, since we have 5 different road signs and 1 person type (total of 6 types) \n","!cat {pipeline_fname}"],"execution_count":15,"outputs":[{"output_type":"stream","text":["# SSD with Mobilenet v1 with quantized training.\n","# Trained on COCO, initialized from Imagenet classification checkpoint\n","\n","# Achieves 18.2 mAP on coco14 minival dataset.\n","\n","# This config is TPU compatible\n","\n","model {\n","  ssd {\n","    inplace_batchnorm_update: true\n","    freeze_batchnorm: false\n","    num_classes: 6\n","    box_coder {\n","      faster_rcnn_box_coder {\n","        y_scale: 10.0\n","        x_scale: 10.0\n","        height_scale: 5.0\n","        width_scale: 5.0\n","      }\n","    }\n","    matcher {\n","      argmax_matcher {\n","        matched_threshold: 0.5\n","        unmatched_threshold: 0.5\n","        ignore_thresholds: false\n","        negatives_lower_than_unmatched: true\n","        force_match_for_each_row: true\n","        use_matmul_gather: true\n","      }\n","    }\n","    similarity_calculator {\n","      iou_similarity {\n","      }\n","    }\n","    encode_background_as_zeros: true\n","    anchor_generator {\n","      ssd_anchor_generator {\n","        num_layers: 6\n","        min_scale: 0.2\n","        max_scale: 0.95\n","        aspect_ratios: 1.0\n","        aspect_ratios: 2.0\n","        aspect_ratios: 0.5\n","        aspect_ratios: 3.0\n","        aspect_ratios: 0.3333\n","      }\n","    }\n","    image_resizer {\n","      fixed_shape_resizer {\n","        height: 300\n","        width: 300\n","      }\n","    }\n","    box_predictor {\n","      convolutional_box_predictor {\n","        min_depth: 0\n","        max_depth: 0\n","        num_layers_before_predictor: 0\n","        use_dropout: false\n","        dropout_keep_probability: 0.8\n","        kernel_size: 1\n","        box_code_size: 4\n","        apply_sigmoid_to_scores: false\n","        class_prediction_bias_init: -4.6\n","        conv_hyperparams {\n","          activation: RELU_6,\n","          regularizer {\n","            l2_regularizer {\n","              weight: 0.00004\n","            }\n","          }\n","          initializer {\n","            random_normal_initializer {\n","              stddev: 0.01\n","              mean: 0.0\n","            }\n","          }\n","          batch_norm {\n","            scale: true,\n","            center: true,\n","            decay: 0.97,\n","            epsilon: 0.001,\n","          }\n","        }\n","      }\n","    }\n","    feature_extractor {\n","      type: 'ssd_mobilenet_v1'\n","      min_depth: 16\n","      depth_multiplier: 1.0\n","      conv_hyperparams {\n","        activation: RELU_6,\n","        regularizer {\n","          l2_regularizer {\n","            weight: 0.00004\n","          }\n","        }\n","        initializer {\n","          random_normal_initializer {\n","            stddev: 0.01\n","            mean: 0.0\n","          }\n","        }\n","        batch_norm {\n","          scale: true,\n","          center: true,\n","          decay: 0.97,\n","          epsilon: 0.001,\n","        }\n","      }\n","      override_base_feature_extractor_hyperparams: true\n","    }\n","    loss {\n","      classification_loss {\n","        weighted_sigmoid_focal {\n","          alpha: 0.75,\n","          gamma: 2.0\n","        }\n","      }\n","      localization_loss {\n","        weighted_smooth_l1 {\n","        }\n","      }\n","      classification_weight: 1.0\n","      localization_weight: 1.0\n","    }\n","    normalize_loss_by_num_matches: true\n","    normalize_loc_loss_by_codesize: true\n","    post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 1e-8\n","        iou_threshold: 0.6\n","        max_detections_per_class: 100\n","        max_total_detections: 100\n","      }\n","      score_converter: SIGMOID\n","    }\n","  }\n","}\n","\n","train_config: {\n","  fine_tune_checkpoint: \"/content/models/research/pretrained_model/model.ckpt\"\n","  batch_size: 12\n","  sync_replicas: true\n","  startup_delay_steps: 0\n","  replicas_to_aggregate: 8\n","  num_steps: 1000\n","  data_augmentation_options {\n","    random_horizontal_flip {\n","    }\n","  }\n","  data_augmentation_options {\n","    ssd_random_crop {\n","    }\n","  }\n","  optimizer {\n","    momentum_optimizer: {\n","      learning_rate: {\n","        cosine_decay_learning_rate {\n","          learning_rate_base: .2\n","          total_steps: 50000\n","          warmup_learning_rate: 0.06\n","          warmup_steps: 2000\n","        }\n","      }\n","      momentum_optimizer_value: 0.9\n","    }\n","    use_moving_average: false\n","  }\n","  max_number_of_boxes: 100\n","  unpad_groundtruth_tensors: false\n","}\n","train_input_reader: {\n","  tf_record_input_reader {\n","    input_path: \"/content/DeepPiCar/models/object_detection/data/annotations/train.record\"\n","  }\n","  label_map_path: \"/content/DeepPiCar/models/object_detection/data/annotations/label_map.pbtxt\"\n","}\n","\n","eval_config: {\n","  metrics_set: \"coco_detection_metrics\"\n","  use_moving_averages: false\n","  num_examples: 8000\n","}\n","\n","eval_input_reader: {\n","  tf_record_input_reader {\n","    input_path: \"/content/DeepPiCar/models/object_detection/data/annotations/test.record\"\n","  }\n","  label_map_path: \"/content/DeepPiCar/models/object_detection/data/annotations/label_map.pbtxt\"\n","  shuffle: false\n","  num_readers: 1\n","}\n","\n","graph_rewriter {\n","  quantization {\n","    delay: 48000\n","    activation_bits: 8\n","    weight_bits: 8\n","  }\n","}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"23TECXvNezIF","colab_type":"text"},"source":["## Run Tensorboard(Optional)"]},{"cell_type":"code","metadata":{"id":"0H2PZs-mSCmO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":243},"executionInfo":{"status":"ok","timestamp":1594562864637,"user_tz":-120,"elapsed":77281,"user":{"displayName":"Clément Nicolas Graffard","photoUrl":"https://lh6.googleusercontent.com/-NkV18IrPyAg/AAAAAAAAAAI/AAAAAAAAH4E/7zBQvWoa2og/s64/photo.jpg","userId":"04495214703013170771"}},"outputId":"7cb84ea4-8139-4b97-a867-4edffbaa4d48"},"source":["!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip -o ngrok-stable-linux-amd64.zip"],"execution_count":16,"outputs":[{"output_type":"stream","text":["--2020-07-12 14:07:37--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","Resolving bin.equinox.io (bin.equinox.io)... 34.225.3.211, 107.23.162.152, 54.85.41.146, ...\n","Connecting to bin.equinox.io (bin.equinox.io)|34.225.3.211|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 13773305 (13M) [application/octet-stream]\n","Saving to: ‘ngrok-stable-linux-amd64.zip.1’\n","\n","ngrok-stable-linux- 100%[===================>]  13.13M  6.08MB/s    in 2.2s    \n","\n","2020-07-12 14:07:40 (6.08 MB/s) - ‘ngrok-stable-linux-amd64.zip.1’ saved [13773305/13773305]\n","\n","Archive:  ngrok-stable-linux-amd64.zip\n","  inflating: ngrok                   \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"G8o6r1o5SC5M","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594562864640,"user_tz":-120,"elapsed":77277,"user":{"displayName":"Clément Nicolas Graffard","photoUrl":"https://lh6.googleusercontent.com/-NkV18IrPyAg/AAAAAAAAAAI/AAAAAAAAH4E/7zBQvWoa2og/s64/photo.jpg","userId":"04495214703013170771"}}},"source":["LOG_DIR = model_dir\n","get_ipython().system_raw(\n","    'tensorboard --logdir \"{}\" --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR)\n",")"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ge1OX7gcSC7S","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594562864642,"user_tz":-120,"elapsed":77274,"user":{"displayName":"Clément Nicolas Graffard","photoUrl":"https://lh6.googleusercontent.com/-NkV18IrPyAg/AAAAAAAAAAI/AAAAAAAAH4E/7zBQvWoa2og/s64/photo.jpg","userId":"04495214703013170771"}}},"source":["get_ipython().system_raw('./ngrok http 6006 &')"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m5GSGxZNh8rp","colab_type":"text"},"source":["### Get Tensorboard link"]},{"cell_type":"code","metadata":{"id":"rjhPT9iPSJ6T","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594562867823,"user_tz":-120,"elapsed":80444,"user":{"displayName":"Clément Nicolas Graffard","photoUrl":"https://lh6.googleusercontent.com/-NkV18IrPyAg/AAAAAAAAAAI/AAAAAAAAH4E/7zBQvWoa2og/s64/photo.jpg","userId":"04495214703013170771"}},"outputId":"670a149f-d9fe-40d4-a366-6a0374313f81"},"source":["! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":19,"outputs":[{"output_type":"stream","text":["https://d7e5d91f24bb.ngrok.io\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JDddx2rPfex9","colab_type":"text"},"source":["## Train the model"]},{"cell_type":"markdown","metadata":{"id":"EZc0RFcUjTa-","colab_type":"text"},"source":["Now all inputs are set up, just train the model.   This process may take a few hours.   Since we are saving the model training results (model.ckpt-* files) in our google drive (a persistent storage that will survice the restart of our colab VM instance), we can safely leave and return a few hours later. "]},{"cell_type":"code","metadata":{"id":"CjDHjhKQofT5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":697},"executionInfo":{"status":"ok","timestamp":1594562874811,"user_tz":-120,"elapsed":87422,"user":{"displayName":"Clément Nicolas Graffard","photoUrl":"https://lh6.googleusercontent.com/-NkV18IrPyAg/AAAAAAAAAAI/AAAAAAAAH4E/7zBQvWoa2og/s64/photo.jpg","userId":"04495214703013170771"}},"outputId":"cd1bab45-b078-43c1-e814-d3cf2707e6e7"},"source":["!python /content/models/research/object_detection/model_main.py \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --model_dir='{model_dir}' \\\n","    --alsologtostderr \\\n","    --num_train_steps={num_steps} \\\n","    --num_eval_steps={num_eval_steps}\n"],"execution_count":20,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n","W0712 14:07:51.699836 139646445533056 model_lib.py:758] Forced number of epochs for all eval validations to be 1.\n","INFO:tensorflow:Maybe overwriting train_steps: 1000\n","I0712 14:07:51.700080 139646445533056 config_util.py:552] Maybe overwriting train_steps: 1000\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I0712 14:07:51.700216 139646445533056 config_util.py:552] Maybe overwriting use_bfloat16: False\n","INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n","I0712 14:07:51.700342 139646445533056 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n","INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n","I0712 14:07:51.700475 139646445533056 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n","WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","W0712 14:07:51.700631 139646445533056 model_lib.py:774] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu None\n","I0712 14:07:51.700789 139646445533056 model_lib.py:809] create_estimator_and_inputs: use_tpu False, export_to_tpu None\n","INFO:tensorflow:Using config: {'_model_dir': '/content/gdrive/My Drive/Colab Notebooks/TransferLearning/Training', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f01901f7f98>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","I0712 14:07:51.701314 139646445533056 estimator.py:212] Using config: {'_model_dir': '/content/gdrive/My Drive/Colab Notebooks/TransferLearning/Training', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f01901f7f98>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f01901e5950>) includes params argument, but params are not passed to Estimator.\n","W0712 14:07:51.702490 139646445533056 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f01901e5950>) includes params argument, but params are not passed to Estimator.\n","INFO:tensorflow:Not using Distribute Coordinator.\n","I0712 14:07:51.703245 139646445533056 estimator_training.py:186] Not using Distribute Coordinator.\n","INFO:tensorflow:Running training and evaluation locally (non-distributed).\n","I0712 14:07:51.703532 139646445533056 training.py:612] Running training and evaluation locally (non-distributed).\n","INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n","I0712 14:07:51.703902 139646445533056 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n","INFO:tensorflow:Skipping training since max_steps has already saved.\n","I0712 14:07:51.714320 139646445533056 estimator.py:363] Skipping training since max_steps has already saved.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KP-tUdtnRybs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"status":"ok","timestamp":1594562878655,"user_tz":-120,"elapsed":91254,"user":{"displayName":"Clément Nicolas Graffard","photoUrl":"https://lh6.googleusercontent.com/-NkV18IrPyAg/AAAAAAAAAAI/AAAAAAAAH4E/7zBQvWoa2og/s64/photo.jpg","userId":"04495214703013170771"}},"outputId":"f37eaccb-f97f-4994-cc0f-6146c5a2dd43"},"source":["!ls -ltra '{model_dir}'"],"execution_count":21,"outputs":[{"output_type":"stream","text":["total 355095\n","-rw------- 1 root root 30104621 Jul 12 13:15 graph.pbtxt\n","-rw------- 1 root root    68804 Jul 12 13:15 model.ckpt-0.index\n","-rw------- 1 root root 75237296 Jul 12 13:15 model.ckpt-0.data-00000-of-00001\n","-rw------- 1 root root 16345178 Jul 12 13:15 model.ckpt-0.meta\n","-rw------- 1 root root    68804 Jul 12 13:25 model.ckpt-1192.index\n","-rw------- 1 root root 75237296 Jul 12 13:25 model.ckpt-1192.data-00000-of-00001\n","-rw------- 1 root root 16345178 Jul 12 13:25 model.ckpt-1192.meta\n","drwx------ 2 root root     4096 Jul 12 13:25 eval_0\n","-rw------- 1 root root    68804 Jul 12 13:32 model.ckpt-2000.index\n","-rw------- 1 root root 75237296 Jul 12 13:32 model.ckpt-2000.data-00000-of-00001\n","-rw------- 1 root root 16345178 Jul 12 13:32 model.ckpt-2000.meta\n","-rw------- 1 root root      176 Jul 12 13:32 checkpoint\n","drwx------ 3 root root     4096 Jul 12 13:32 export\n","-rw------- 1 root root 58542083 Jul 12 13:32 events.out.tfevents.1594559702.ad0b2401e9eb\n","drwx------ 3 root root     4096 Jul 12 14:04 fine_tuned_model\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"y4Kzh3_JLVW-","colab_type":"text"},"source":["# Section 5: Save and Convert Model Output"]},{"cell_type":"markdown","metadata":{"id":"OmSESMetj1sa","colab_type":"text"},"source":["## Exporting a Trained Inference Graph\n","Once your training job is complete, you need to extract the newly trained inference graph, which will be later used to perform the object detection. This can be done as follows:"]},{"cell_type":"code","metadata":{"id":"DHoP90pUyKSq","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594562878657,"user_tz":-120,"elapsed":91250,"user":{"displayName":"Clément Nicolas Graffard","photoUrl":"https://lh6.googleusercontent.com/-NkV18IrPyAg/AAAAAAAAAAI/AAAAAAAAH4E/7zBQvWoa2og/s64/photo.jpg","userId":"04495214703013170771"}}},"source":["import os\n","import re\n","import numpy as np\n","\n","output_directory = '%s/fine_tuned_model' % model_dir\n","os.makedirs(output_directory, exist_ok=True)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"ikck2kvh_wTB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594562878658,"user_tz":-120,"elapsed":91242,"user":{"displayName":"Clément Nicolas Graffard","photoUrl":"https://lh6.googleusercontent.com/-NkV18IrPyAg/AAAAAAAAAAI/AAAAAAAAH4E/7zBQvWoa2og/s64/photo.jpg","userId":"04495214703013170771"}},"outputId":"f88413d9-ff41-4cb9-cb37-6d11b3b2b974"},"source":["lst = os.listdir(model_dir)\n","# find the last model checkpoint file, i.e. model.ckpt-1000.meta\n","lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n","steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n","last_model = lst[steps.argmax()].replace('.meta', '')\n","\n","last_model_path = os.path.join(model_dir, last_model)\n","print(last_model_path)\n"],"execution_count":23,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/Colab Notebooks/TransferLearning/Training/model.ckpt-2000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hlxqSTTgHMHO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594562896981,"user_tz":-120,"elapsed":109552,"user":{"displayName":"Clément Nicolas Graffard","photoUrl":"https://lh6.googleusercontent.com/-NkV18IrPyAg/AAAAAAAAAAI/AAAAAAAAH4E/7zBQvWoa2og/s64/photo.jpg","userId":"04495214703013170771"}},"outputId":"f7261053-fa64-473a-a80b-90f2709e6ce6"},"source":["!echo creates the frozen inference graph in fine_tune_model\n","# there is an \"Incomplete shape\" message.  but we can safely ignore that. \n","!python /content/models/research/object_detection/export_inference_graph.py \\\n","    --input_type=image_tensor \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --output_directory='{output_directory}' \\\n","    --trained_checkpoint_prefix='{last_model_path}'"],"execution_count":24,"outputs":[{"output_type":"stream","text":["creates the frozen inference graph in fine_tune_model\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W0712 14:08:07.707870 140345903196032 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0712 14:08:09.482139 140345903196032 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0712 14:08:09.528363 140345903196032 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0712 14:08:09.572879 140345903196032 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0712 14:08:09.616602 140345903196032 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0712 14:08:09.660711 140345903196032 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0712 14:08:09.705050 140345903196032 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /content/models/research/object_detection/core/post_processing.py:583: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0712 14:08:10.029518 140345903196032 deprecation.py:323] From /content/models/research/object_detection/core/post_processing.py:583: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","W0712 14:08:10.755194 140345903196032 deprecation.py:323] From /content/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/add_fold\n","I0712 14:08:11.882071 140345903196032 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/add_fold\n","I0712 14:08:11.882459 140345903196032 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_pointwise/add_fold\n","I0712 14:08:11.882743 140345903196032 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/add_fold\n","I0712 14:08:11.882997 140345903196032 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_pointwise/add_fold\n","I0712 14:08:11.883237 140345903196032 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/add_fold\n","I0712 14:08:11.883486 140345903196032 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_pointwise/add_fold\n","I0712 14:08:11.883744 140345903196032 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/add_fold\n","I0712 14:08:11.884012 140345903196032 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_pointwise/add_fold\n","I0712 14:08:11.884270 140345903196032 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/add_fold\n","I0712 14:08:11.884522 140345903196032 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_pointwise/add_fold\n","I0712 14:08:11.884774 140345903196032 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/add_fold\n","I0712 14:08:11.884999 140345903196032 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_pointwise/add_fold\n","I0712 14:08:11.885229 140345903196032 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/add_fold\n","I0712 14:08:11.885471 140345903196032 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_pointwise/add_fold\n","I0712 14:08:11.885705 140345903196032 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/add_fold\n","I0712 14:08:11.885980 140345903196032 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_pointwise/add_fold\n","I0712 14:08:11.886229 140345903196032 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/add_fold\n","I0712 14:08:11.886535 140345903196032 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_pointwise/add_fold\n","I0712 14:08:11.886806 140345903196032 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/add_fold\n","I0712 14:08:11.887031 140345903196032 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_pointwise/add_fold\n","I0712 14:08:11.887260 140345903196032 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/add_fold\n","I0712 14:08:11.887500 140345903196032 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_pointwise/add_fold\n","I0712 14:08:11.887737 140345903196032 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/add_fold\n","I0712 14:08:11.887969 140345903196032 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_pointwise/add_fold\n","I0712 14:08:11.888192 140345903196032 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/add_fold\n","I0712 14:08:11.888431 140345903196032 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_pointwise/add_fold\n","I0712 14:08:11.888654 140345903196032 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/add_fold\n","I0712 14:08:11.888952 140345903196032 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/add_fold\n","I0712 14:08:11.889225 140345903196032 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/add_fold\n","I0712 14:08:11.889530 140345903196032 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/add_fold\n","I0712 14:08:11.889883 140345903196032 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/add_fold\n","I0712 14:08:11.890201 140345903196032 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/add_fold\n","I0712 14:08:11.890532 140345903196032 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/add_fold\n","I0712 14:08:11.891072 140345903196032 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/add_fold\n","I0712 14:08:11.891393 140345903196032 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/add_fold\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n","Instructions for updating:\n","Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n","W0712 14:08:11.894113 140345903196032 deprecation.py:323] From /content/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n","Instructions for updating:\n","Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","W0712 14:08:11.894964 140345903196032 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","188 ops no flops stats due to incomplete shapes.\n","Parsing Inputs...\n","Incomplete shape.\n","\n","=========================Options=============================\n","-max_depth                  10000\n","-min_bytes                  0\n","-min_peak_bytes             0\n","-min_residual_bytes         0\n","-min_output_bytes           0\n","-min_micros                 0\n","-min_accelerator_micros     0\n","-min_cpu_micros             0\n","-min_params                 0\n","-min_float_ops              0\n","-min_occurrence             0\n","-step                       -1\n","-order_by                   name\n","-account_type_regexes       _trainable_variables\n","-start_name_regexes         .*\n","-trim_name_regexes          .*BatchNorm.*\n","-show_name_regexes          .*\n","-hide_name_regexes          \n","-account_displayed_op_only  true\n","-select                     params\n","-output                     stdout:\n","\n","==================Model Analysis Report======================\n","Incomplete shape.\n","\n","Doc:\n","scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n","param: Number of parameters (in the Variable).\n","\n","Profile:\n","node name | # parameters\n","_TFProfRoot (--/5.57m params)\n","  BoxPredictor_0 (--/16.93k params)\n","    BoxPredictor_0/BoxEncodingPredictor (--/6.16k params)\n","      BoxPredictor_0/BoxEncodingPredictor/biases (12, 12/12 params)\n","      BoxPredictor_0/BoxEncodingPredictor/weights (1x1x512x12, 6.14k/6.14k params)\n","    BoxPredictor_0/ClassPredictor (--/10.77k params)\n","      BoxPredictor_0/ClassPredictor/biases (21, 21/21 params)\n","      BoxPredictor_0/ClassPredictor/weights (1x1x512x21, 10.75k/10.75k params)\n","  BoxPredictor_1 (--/67.65k params)\n","    BoxPredictor_1/BoxEncodingPredictor (--/24.60k params)\n","      BoxPredictor_1/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_1/BoxEncodingPredictor/weights (1x1x1024x24, 24.58k/24.58k params)\n","    BoxPredictor_1/ClassPredictor (--/43.05k params)\n","      BoxPredictor_1/ClassPredictor/biases (42, 42/42 params)\n","      BoxPredictor_1/ClassPredictor/weights (1x1x1024x42, 43.01k/43.01k params)\n","  BoxPredictor_2 (--/33.86k params)\n","    BoxPredictor_2/BoxEncodingPredictor (--/12.31k params)\n","      BoxPredictor_2/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_2/BoxEncodingPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n","    BoxPredictor_2/ClassPredictor (--/21.55k params)\n","      BoxPredictor_2/ClassPredictor/biases (42, 42/42 params)\n","      BoxPredictor_2/ClassPredictor/weights (1x1x512x42, 21.50k/21.50k params)\n","  BoxPredictor_3 (--/16.96k params)\n","    BoxPredictor_3/BoxEncodingPredictor (--/6.17k params)\n","      BoxPredictor_3/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_3/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n","    BoxPredictor_3/ClassPredictor (--/10.79k params)\n","      BoxPredictor_3/ClassPredictor/biases (42, 42/42 params)\n","      BoxPredictor_3/ClassPredictor/weights (1x1x256x42, 10.75k/10.75k params)\n","  BoxPredictor_4 (--/16.96k params)\n","    BoxPredictor_4/BoxEncodingPredictor (--/6.17k params)\n","      BoxPredictor_4/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_4/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n","    BoxPredictor_4/ClassPredictor (--/10.79k params)\n","      BoxPredictor_4/ClassPredictor/biases (42, 42/42 params)\n","      BoxPredictor_4/ClassPredictor/weights (1x1x256x42, 10.75k/10.75k params)\n","  BoxPredictor_5 (--/8.51k params)\n","    BoxPredictor_5/BoxEncodingPredictor (--/3.10k params)\n","      BoxPredictor_5/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_5/BoxEncodingPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n","    BoxPredictor_5/ClassPredictor (--/5.42k params)\n","      BoxPredictor_5/ClassPredictor/biases (42, 42/42 params)\n","      BoxPredictor_5/ClassPredictor/weights (1x1x128x42, 5.38k/5.38k params)\n","  FeatureExtractor (--/5.41m params)\n","    FeatureExtractor/MobilenetV1 (--/5.41m params)\n","      FeatureExtractor/MobilenetV1/Conv2d_0 (--/864 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_0/weights (3x3x3x32, 864/864 params)\n","      FeatureExtractor/MobilenetV1/Conv2d_10_depthwise (--/4.61k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_10_pointwise (--/262.14k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_11_depthwise (--/4.61k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_11_pointwise (--/262.14k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_12_depthwise (--/4.61k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_12_pointwise (--/524.29k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/weights (1x1x512x1024, 524.29k/524.29k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_13_depthwise (--/9.22k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/depthwise_weights (3x3x1024x1, 9.22k/9.22k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise (--/1.05m params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/weights (1x1x1024x1024, 1.05m/1.05m params)\n","      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256 (--/262.14k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/weights (1x1x1024x256, 262.14k/262.14k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128 (--/65.54k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/weights (1x1x512x128, 65.54k/65.54k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128 (--/32.77k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/weights (1x1x256x128, 32.77k/32.77k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64 (--/16.38k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/weights (1x1x256x64, 16.38k/16.38k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512 (--/1.18m params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/weights (3x3x256x512, 1.18m/1.18m params)\n","      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256 (--/294.91k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256 (--/294.91k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128 (--/73.73k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/weights (3x3x64x128, 73.73k/73.73k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_1_depthwise (--/288 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/depthwise_weights (3x3x32x1, 288/288 params)\n","      FeatureExtractor/MobilenetV1/Conv2d_1_pointwise (--/2.05k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/weights (1x1x32x64, 2.05k/2.05k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_2_depthwise (--/576 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/depthwise_weights (3x3x64x1, 576/576 params)\n","      FeatureExtractor/MobilenetV1/Conv2d_2_pointwise (--/8.19k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/weights (1x1x64x128, 8.19k/8.19k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_3_depthwise (--/1.15k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_3_pointwise (--/16.38k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/weights (1x1x128x128, 16.38k/16.38k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_4_depthwise (--/1.15k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_4_pointwise (--/32.77k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/weights (1x1x128x256, 32.77k/32.77k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_5_depthwise (--/2.30k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_5_pointwise (--/65.54k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/weights (1x1x256x256, 65.54k/65.54k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_6_depthwise (--/2.30k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_6_pointwise (--/131.07k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/weights (1x1x256x512, 131.07k/131.07k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_7_depthwise (--/4.61k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_7_pointwise (--/262.14k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_8_depthwise (--/4.61k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_8_pointwise (--/262.14k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_9_depthwise (--/4.61k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n","      FeatureExtractor/MobilenetV1/Conv2d_9_pointwise (--/262.14k params)\n","        FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n","\n","======================End of Report==========================\n","188 ops no flops stats due to incomplete shapes.\n","Parsing Inputs...\n","Incomplete shape.\n","\n","=========================Options=============================\n","-max_depth                  10000\n","-min_bytes                  0\n","-min_peak_bytes             0\n","-min_residual_bytes         0\n","-min_output_bytes           0\n","-min_micros                 0\n","-min_accelerator_micros     0\n","-min_cpu_micros             0\n","-min_params                 0\n","-min_float_ops              1\n","-min_occurrence             0\n","-step                       -1\n","-order_by                   float_ops\n","-account_type_regexes       .*\n","-start_name_regexes         .*\n","-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n","-show_name_regexes          .*\n","-hide_name_regexes          \n","-account_displayed_op_only  true\n","-select                     float_ops\n","-output                     stdout:\n","\n","==================Model Analysis Report======================\n","Incomplete shape.\n","\n","Doc:\n","scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n","flops: Number of float operations. Note: Please read the implementation for the math behind it.\n","\n","Profile:\n","node name | # float_ops\n","_TFProfRoot (--/5.42m flops)\n","  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/mul_fold (1.18m/1.18m flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_pointwise/mul_fold (1.05m/1.05m flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_pointwise/mul_fold (524.29k/524.29k flops)\n","  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/mul_fold (294.91k/294.91k flops)\n","  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/mul_fold (294.91k/294.91k flops)\n","  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/mul_fold (262.14k/262.14k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_pointwise/mul_fold (262.14k/262.14k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_pointwise/mul_fold (262.14k/262.14k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_pointwise/mul_fold (262.14k/262.14k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_pointwise/mul_fold (262.14k/262.14k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_pointwise/mul_fold (262.14k/262.14k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_pointwise/mul_fold (131.07k/131.07k flops)\n","  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/mul_fold (73.73k/73.73k flops)\n","  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/mul_fold (65.54k/65.54k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_pointwise/mul_fold (65.54k/65.54k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_pointwise/mul_fold (32.77k/32.77k flops)\n","  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/mul_fold (32.77k/32.77k flops)\n","  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/mul_fold (16.38k/16.38k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_pointwise/mul_fold (16.38k/16.38k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/mul_fold (9.22k/9.22k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_pointwise/mul_fold (8.19k/8.19k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/mul_fold (4.61k/4.61k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/mul_fold (4.61k/4.61k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/mul_fold (4.61k/4.61k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/mul_fold (4.61k/4.61k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/mul_fold (4.61k/4.61k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/mul_fold (4.61k/4.61k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/mul_fold (2.30k/2.30k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/mul_fold (2.30k/2.30k flops)\n","  MultipleGridAnchorGenerator/mul_19 (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/mul_20 (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/sub (2.17k/2.17k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_pointwise/mul_fold (2.05k/2.05k flops)\n","  MultipleGridAnchorGenerator/sub_1 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/mul_27 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/mul_28 (1.20k/1.20k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/mul_fold (1.15k/1.15k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/mul_fold (1.15k/1.15k flops)\n","  MultipleGridAnchorGenerator/mul_21 (1.08k/1.08k flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/mul_fold (864/864 flops)\n","  MultipleGridAnchorGenerator/mul_29 (600/600 flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/mul_fold (576/576 flops)\n","  MultipleGridAnchorGenerator/mul_35 (300/300 flops)\n","  MultipleGridAnchorGenerator/mul_36 (300/300 flops)\n","  MultipleGridAnchorGenerator/sub_2 (300/300 flops)\n","  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/mul_fold (288/288 flops)\n","  MultipleGridAnchorGenerator/mul_37 (150/150 flops)\n","  MultipleGridAnchorGenerator/mul_44 (108/108 flops)\n","  MultipleGridAnchorGenerator/mul_43 (108/108 flops)\n","  MultipleGridAnchorGenerator/sub_3 (108/108 flops)\n","  MultipleGridAnchorGenerator/mul_45 (54/54 flops)\n","  MultipleGridAnchorGenerator/mul_51 (48/48 flops)\n","  MultipleGridAnchorGenerator/mul_52 (48/48 flops)\n","  MultipleGridAnchorGenerator/sub_4 (48/48 flops)\n","  MultipleGridAnchorGenerator/mul_53 (24/24 flops)\n","  MultipleGridAnchorGenerator/mul_17 (19/19 flops)\n","  MultipleGridAnchorGenerator/mul_18 (19/19 flops)\n","  MultipleGridAnchorGenerator/sub_5 (12/12 flops)\n","  MultipleGridAnchorGenerator/mul_59 (12/12 flops)\n","  MultipleGridAnchorGenerator/mul_60 (12/12 flops)\n","  MultipleGridAnchorGenerator/mul_26 (10/10 flops)\n","  MultipleGridAnchorGenerator/mul_25 (10/10 flops)\n","  MultipleGridAnchorGenerator/mul_38 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_19 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_46 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_47 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_48 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_18 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_17 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_16 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_54 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_55 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_56 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_15 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_61 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_40 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_39 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_22 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_23 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_32 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_31 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_30 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_24 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_34 (5/5 flops)\n","  MultipleGridAnchorGenerator/mul_33 (5/5 flops)\n","  MultipleGridAnchorGenerator/mul_41 (3/3 flops)\n","  MultipleGridAnchorGenerator/truediv_14 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_14 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_15 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_16 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_42 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_50 (2/2 flops)\n","  MultipleGridAnchorGenerator/mul_49 (2/2 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_8 (1/1 flops)\n","  Preprocessor/map/while/Less (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_11 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_6 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_10 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n","  Preprocessor/map/while/Less_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_5 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_12 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_11 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_10 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_9 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_8 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_7 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_6 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_58 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_57 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_13 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_4 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_3 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_2 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_13 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_12 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_11 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_10 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul (1/1 flops)\n","  MultipleGridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n","  MultipleGridAnchorGenerator/Minimum (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_6 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_9 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_8 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_7 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_6 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_5 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_4 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_3 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_2 (1/1 flops)\n","\n","======================End of Report==========================\n","2020-07-12 14:08:14.693125: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-07-12 14:08:14.712854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:14.713597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n","pciBusID: 0000:00:04.0\n","2020-07-12 14:08:14.713931: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-07-12 14:08:14.715786: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-07-12 14:08:14.717736: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-07-12 14:08:14.718071: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-07-12 14:08:14.720255: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-07-12 14:08:14.721391: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-07-12 14:08:14.726026: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-07-12 14:08:14.726228: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:14.727080: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:14.728017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-07-12 14:08:14.734138: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n","2020-07-12 14:08:14.734408: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2824d80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-07-12 14:08:14.734445: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-07-12 14:08:14.791080: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:14.791954: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2825100 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-07-12 14:08:14.791988: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n","2020-07-12 14:08:14.792229: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:14.792993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n","pciBusID: 0000:00:04.0\n","2020-07-12 14:08:14.793069: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-07-12 14:08:14.793111: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-07-12 14:08:14.793152: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-07-12 14:08:14.793202: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-07-12 14:08:14.793243: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-07-12 14:08:14.793280: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-07-12 14:08:14.793352: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-07-12 14:08:14.793507: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:14.794364: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:14.795088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-07-12 14:08:14.795205: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-07-12 14:08:14.796910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-07-12 14:08:14.796941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-07-12 14:08:14.796957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-07-12 14:08:14.797159: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:14.797996: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:14.798737: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-07-12 14:08:14.798786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n","INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/Colab Notebooks/TransferLearning/Training/model.ckpt-2000\n","I0712 14:08:14.802109 140345903196032 saver.py:1284] Restoring parameters from /content/gdrive/My Drive/Colab Notebooks/TransferLearning/Training/model.ckpt-2000\n","2020-07-12 14:08:15.344051: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at save_restore_v2_ops.cc:184 : Not found: Key FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/beta not found in checkpoint\n","Traceback (most recent call last):\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n","    return fn(*args)\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n","    target_list, run_metadata)\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n","    run_metadata)\n","tensorflow.python.framework.errors_impl.NotFoundError: 2 root error(s) found.\n","  (0) Not found: Key FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/beta not found in checkpoint\n","\t [[{{node save/RestoreV2}}]]\n","\t [[save/RestoreV2/_301]]\n","  (1) Not found: Key FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/beta not found in checkpoint\n","\t [[{{node save/RestoreV2}}]]\n","0 successful operations.\n","0 derived errors ignored.\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py\", line 1290, in restore\n","    {self.saver_def.filename_tensor_name: save_path})\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 956, in run\n","    run_metadata_ptr)\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1180, in _run\n","    feed_dict_tensor, options, run_metadata)\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n","    run_metadata)\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1384, in _do_call\n","    raise type(e)(node_def, op, message)\n","tensorflow.python.framework.errors_impl.NotFoundError: 2 root error(s) found.\n","  (0) Not found: Key FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/beta not found in checkpoint\n","\t [[node save/RestoreV2 (defined at tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py:1748) ]]\n","\t [[save/RestoreV2/_301]]\n","  (1) Not found: Key FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/beta not found in checkpoint\n","\t [[node save/RestoreV2 (defined at tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py:1748) ]]\n","0 successful operations.\n","0 derived errors ignored.\n","\n","Original stack trace for 'save/RestoreV2':\n","  File \"content/models/research/object_detection/export_inference_graph.py\", line 206, in <module>\n","    tf.app.run()\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/platform/app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n","    _run_main(main, args)\n","  File \"usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n","    sys.exit(main(argv))\n","  File \"content/models/research/object_detection/export_inference_graph.py\", line 202, in main\n","    side_input_types=side_input_types)\n","  File \"content/models/research/object_detection/exporter.py\", line 625, in export_inference_graph\n","    side_input_types=side_input_types)\n","  File \"content/models/research/object_detection/exporter.py\", line 538, in _export_inference_graph\n","    trained_checkpoint_prefix=checkpoint_to_use)\n","  File \"content/models/research/object_detection/exporter.py\", line 419, in write_graph_and_checkpoint\n","    tf.import_graph_def(inference_graph_def, name='')\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n","    return func(*args, **kwargs)\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/importer.py\", line 405, in import_graph_def\n","    producer_op_list=producer_op_list)\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/importer.py\", line 517, in _import_graph_def_internal\n","    _ProcessNewOps(graph)\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/importer.py\", line 243, in _ProcessNewOps\n","    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 3561, in _add_new_tf_operations\n","    for c_op in c_api_util.new_tf_operations(self)\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 3561, in <listcomp>\n","    for c_op in c_api_util.new_tf_operations(self)\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 3451, in _create_op_from_tf_operation\n","    ret = Operation(c_op, self)\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n","    self._traceback = tf_stack.extract_stack()\n","\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py\", line 1300, in restore\n","    names_to_keys = object_graph_key_mapping(save_path)\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py\", line 1618, in object_graph_key_mapping\n","    object_graph_string = reader.get_tensor(trackable.OBJECT_GRAPH_PROTO_KEY)\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/pywrap_tensorflow_internal.py\", line 915, in get_tensor\n","    return CheckpointReader_GetTensor(self, compat.as_bytes(tensor_str))\n","tensorflow.python.framework.errors_impl.NotFoundError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/content/models/research/object_detection/export_inference_graph.py\", line 206, in <module>\n","    tf.app.run()\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/platform/app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n","    sys.exit(main(argv))\n","  File \"/content/models/research/object_detection/export_inference_graph.py\", line 202, in main\n","    side_input_types=side_input_types)\n","  File \"/content/models/research/object_detection/exporter.py\", line 625, in export_inference_graph\n","    side_input_types=side_input_types)\n","  File \"/content/models/research/object_detection/exporter.py\", line 538, in _export_inference_graph\n","    trained_checkpoint_prefix=checkpoint_to_use)\n","  File \"/content/models/research/object_detection/exporter.py\", line 423, in write_graph_and_checkpoint\n","    saver.restore(sess, trained_checkpoint_prefix)\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py\", line 1306, in restore\n","    err, \"a Variable name or other graph key that is missing\")\n","tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n","\n","2 root error(s) found.\n","  (0) Not found: Key FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/beta not found in checkpoint\n","\t [[node save/RestoreV2 (defined at tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py:1748) ]]\n","\t [[save/RestoreV2/_301]]\n","  (1) Not found: Key FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/beta not found in checkpoint\n","\t [[node save/RestoreV2 (defined at tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py:1748) ]]\n","0 successful operations.\n","0 derived errors ignored.\n","\n","Original stack trace for 'save/RestoreV2':\n","  File \"content/models/research/object_detection/export_inference_graph.py\", line 206, in <module>\n","    tf.app.run()\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/platform/app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n","    _run_main(main, args)\n","  File \"usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n","    sys.exit(main(argv))\n","  File \"content/models/research/object_detection/export_inference_graph.py\", line 202, in main\n","    side_input_types=side_input_types)\n","  File \"content/models/research/object_detection/exporter.py\", line 625, in export_inference_graph\n","    side_input_types=side_input_types)\n","  File \"content/models/research/object_detection/exporter.py\", line 538, in _export_inference_graph\n","    trained_checkpoint_prefix=checkpoint_to_use)\n","  File \"content/models/research/object_detection/exporter.py\", line 419, in write_graph_and_checkpoint\n","    tf.import_graph_def(inference_graph_def, name='')\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n","    return func(*args, **kwargs)\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/importer.py\", line 405, in import_graph_def\n","    producer_op_list=producer_op_list)\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/importer.py\", line 517, in _import_graph_def_internal\n","    _ProcessNewOps(graph)\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/importer.py\", line 243, in _ProcessNewOps\n","    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 3561, in _add_new_tf_operations\n","    for c_op in c_api_util.new_tf_operations(self)\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 3561, in <listcomp>\n","    for c_op in c_api_util.new_tf_operations(self)\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 3451, in _create_op_from_tf_operation\n","    ret = Operation(c_op, self)\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n","    self._traceback = tf_stack.extract_stack()\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kwsBovsWZV_S","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594562908758,"user_tz":-120,"elapsed":121319,"user":{"displayName":"Clément Nicolas Graffard","photoUrl":"https://lh6.googleusercontent.com/-NkV18IrPyAg/AAAAAAAAAAI/AAAAAAAAH4E/7zBQvWoa2og/s64/photo.jpg","userId":"04495214703013170771"}},"outputId":"f8b728c4-698b-496b-e4ef-66dda2db1974"},"source":["# https://medium.com/tensorflow/training-and-serving-a-realtime-mobile-object-detector-in-30-minutes-with-cloud-tpus-b78971cf1193\n","# create the tensorflow lite graph\n","!python /content/models/research/object_detection/export_tflite_ssd_graph.py \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --trained_checkpoint_prefix='{last_model_path}' \\\n","    --output_directory='{output_directory}' \\\n","    --add_postprocessing_op=true"],"execution_count":25,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W0712 14:08:21.171990 140166391416704 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0712 14:08:22.956791 140166391416704 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0712 14:08:22.993882 140166391416704 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0712 14:08:23.029981 140166391416704 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0712 14:08:23.071691 140166391416704 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0712 14:08:23.108472 140166391416704 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0712 14:08:23.143704 140166391416704 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","2020-07-12 14:08:23.194314: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-07-12 14:08:23.215106: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:23.215992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n","pciBusID: 0000:00:04.0\n","2020-07-12 14:08:23.216391: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-07-12 14:08:23.218318: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-07-12 14:08:23.220393: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-07-12 14:08:23.220868: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-07-12 14:08:23.223180: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-07-12 14:08:23.224374: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-07-12 14:08:23.228349: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-07-12 14:08:23.228528: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:23.229345: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:23.230143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-07-12 14:08:23.235709: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n","2020-07-12 14:08:23.235945: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x136ad80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-07-12 14:08:23.235981: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-07-12 14:08:23.289763: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:23.290605: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x136abc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-07-12 14:08:23.290639: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n","2020-07-12 14:08:23.290878: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:23.291609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n","pciBusID: 0000:00:04.0\n","2020-07-12 14:08:23.291695: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-07-12 14:08:23.291762: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-07-12 14:08:23.291813: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-07-12 14:08:23.291856: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-07-12 14:08:23.291895: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-07-12 14:08:23.291938: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-07-12 14:08:23.291981: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-07-12 14:08:23.292108: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:23.292935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:23.293645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-07-12 14:08:23.293712: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-07-12 14:08:23.295378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-07-12 14:08:23.295414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-07-12 14:08:23.295442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-07-12 14:08:23.295606: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:23.296435: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:23.297179: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-07-12 14:08:23.297233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/add_fold\n","I0712 14:08:24.612467 140166391416704 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/add_fold\n","I0712 14:08:24.612842 140166391416704 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_pointwise/add_fold\n","I0712 14:08:24.613080 140166391416704 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/add_fold\n","I0712 14:08:24.613366 140166391416704 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_pointwise/add_fold\n","I0712 14:08:24.613589 140166391416704 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/add_fold\n","I0712 14:08:24.613858 140166391416704 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_pointwise/add_fold\n","I0712 14:08:24.614081 140166391416704 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/add_fold\n","I0712 14:08:24.614320 140166391416704 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_pointwise/add_fold\n","I0712 14:08:24.614548 140166391416704 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/add_fold\n","I0712 14:08:24.614817 140166391416704 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_pointwise/add_fold\n","I0712 14:08:24.615037 140166391416704 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/add_fold\n","I0712 14:08:24.615303 140166391416704 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_pointwise/add_fold\n","I0712 14:08:24.615543 140166391416704 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/add_fold\n","I0712 14:08:24.615801 140166391416704 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_pointwise/add_fold\n","I0712 14:08:24.616017 140166391416704 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/add_fold\n","I0712 14:08:24.616250 140166391416704 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_pointwise/add_fold\n","I0712 14:08:24.616473 140166391416704 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/add_fold\n","I0712 14:08:24.616705 140166391416704 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_pointwise/add_fold\n","I0712 14:08:24.616940 140166391416704 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/add_fold\n","I0712 14:08:24.617182 140166391416704 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_pointwise/add_fold\n","I0712 14:08:24.617428 140166391416704 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/add_fold\n","I0712 14:08:24.617658 140166391416704 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_pointwise/add_fold\n","I0712 14:08:24.617932 140166391416704 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/add_fold\n","I0712 14:08:24.618176 140166391416704 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_pointwise/add_fold\n","I0712 14:08:24.618393 140166391416704 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/add_fold\n","I0712 14:08:24.618640 140166391416704 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_pointwise/add_fold\n","I0712 14:08:24.618914 140166391416704 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_pointwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/add_fold\n","I0712 14:08:24.619138 140166391416704 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/add_fold\n","I0712 14:08:24.619365 140166391416704 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/add_fold\n","I0712 14:08:24.619683 140166391416704 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/add_fold\n","I0712 14:08:24.620030 140166391416704 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/add_fold\n","I0712 14:08:24.620379 140166391416704 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/add_fold\n","I0712 14:08:24.620750 140166391416704 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/add_fold\n","I0712 14:08:24.621029 140166391416704 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/add_fold\n","I0712 14:08:24.621286 140166391416704 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/add_fold\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","W0712 14:08:25.009326 140166391416704 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","2020-07-12 14:08:25.608369: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:25.609263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n","pciBusID: 0000:00:04.0\n","2020-07-12 14:08:25.609370: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-07-12 14:08:25.609413: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-07-12 14:08:25.609465: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-07-12 14:08:25.609523: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-07-12 14:08:25.609560: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-07-12 14:08:25.609609: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-07-12 14:08:25.609656: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-07-12 14:08:25.609811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:25.610633: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:25.611388: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-07-12 14:08:25.611438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-07-12 14:08:25.611463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-07-12 14:08:25.611478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-07-12 14:08:25.611635: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:25.612425: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:25.613141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n","INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/Colab Notebooks/TransferLearning/Training/model.ckpt-2000\n","I0712 14:08:25.615314 140166391416704 saver.py:1284] Restoring parameters from /content/gdrive/My Drive/Colab Notebooks/TransferLearning/Training/model.ckpt-2000\n","2020-07-12 14:08:26.213290: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at save_restore_v2_ops.cc:184 : Not found: Key FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/beta not found in checkpoint\n","Traceback (most recent call last):\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n","    return fn(*args)\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n","    target_list, run_metadata)\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n","    run_metadata)\n","tensorflow.python.framework.errors_impl.NotFoundError: 2 root error(s) found.\n","  (0) Not found: Key FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/beta not found in checkpoint\n","\t [[{{node save/RestoreV2}}]]\n","\t [[save/RestoreV2/_301]]\n","  (1) Not found: Key FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/beta not found in checkpoint\n","\t [[{{node save/RestoreV2}}]]\n","0 successful operations.\n","0 derived errors ignored.\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py\", line 1290, in restore\n","    {self.saver_def.filename_tensor_name: save_path})\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 956, in run\n","    run_metadata_ptr)\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1180, in _run\n","    feed_dict_tensor, options, run_metadata)\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n","    run_metadata)\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1384, in _do_call\n","    raise type(e)(node_def, op, message)\n","tensorflow.python.framework.errors_impl.NotFoundError: 2 root error(s) found.\n","  (0) Not found: Key FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/beta not found in checkpoint\n","\t [[node save/RestoreV2 (defined at tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py:1748) ]]\n","\t [[save/RestoreV2/_301]]\n","  (1) Not found: Key FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/beta not found in checkpoint\n","\t [[node save/RestoreV2 (defined at tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py:1748) ]]\n","0 successful operations.\n","0 derived errors ignored.\n","\n","Original stack trace for 'save/RestoreV2':\n","  File \"content/models/research/object_detection/export_tflite_ssd_graph.py\", line 144, in <module>\n","    tf.app.run(main)\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/platform/app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n","    _run_main(main, args)\n","  File \"usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n","    sys.exit(main(argv))\n","  File \"content/models/research/object_detection/export_tflite_ssd_graph.py\", line 140, in main\n","    FLAGS.max_classes_per_detection, use_regular_nms=FLAGS.use_regular_nms)\n","  File \"content/models/research/object_detection/export_tflite_ssd_graph_lib.py\", line 296, in export_tflite_graph\n","    saver = tf.train.Saver(**saver_kwargs)\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py\", line 828, in __init__\n","    self.build()\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py\", line 840, in build\n","    self._build(self._filename, build_save=True, build_restore=True)\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py\", line 878, in _build\n","    build_restore=build_restore)\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py\", line 508, in _build_internal\n","    restore_sequentially, reshape)\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py\", line 328, in _AddRestoreOps\n","    restore_sequentially)\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py\", line 575, in bulk_restore\n","    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/gen_io_ops.py\", line 1696, in restore_v2\n","    name=name)\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n","    op_def=op_def)\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n","    return func(*args, **kwargs)\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n","    attrs, op_def, compute_device)\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n","    op_def=op_def)\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n","    self._traceback = tf_stack.extract_stack()\n","\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py\", line 1300, in restore\n","    names_to_keys = object_graph_key_mapping(save_path)\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py\", line 1618, in object_graph_key_mapping\n","    object_graph_string = reader.get_tensor(trackable.OBJECT_GRAPH_PROTO_KEY)\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/pywrap_tensorflow_internal.py\", line 915, in get_tensor\n","    return CheckpointReader_GetTensor(self, compat.as_bytes(tensor_str))\n","tensorflow.python.framework.errors_impl.NotFoundError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/content/models/research/object_detection/export_tflite_ssd_graph.py\", line 144, in <module>\n","    tf.app.run(main)\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/platform/app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n","    sys.exit(main(argv))\n","  File \"/content/models/research/object_detection/export_tflite_ssd_graph.py\", line 140, in main\n","    FLAGS.max_classes_per_detection, use_regular_nms=FLAGS.use_regular_nms)\n","  File \"/content/models/research/object_detection/export_tflite_ssd_graph_lib.py\", line 310, in export_tflite_graph\n","    initializer_nodes='')\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py\", line 151, in freeze_graph_with_def_protos\n","    saver.restore(sess, input_checkpoint)\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py\", line 1306, in restore\n","    err, \"a Variable name or other graph key that is missing\")\n","tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n","\n","2 root error(s) found.\n","  (0) Not found: Key FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/beta not found in checkpoint\n","\t [[node save/RestoreV2 (defined at tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py:1748) ]]\n","\t [[save/RestoreV2/_301]]\n","  (1) Not found: Key FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/beta not found in checkpoint\n","\t [[node save/RestoreV2 (defined at tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py:1748) ]]\n","0 successful operations.\n","0 derived errors ignored.\n","\n","Original stack trace for 'save/RestoreV2':\n","  File \"content/models/research/object_detection/export_tflite_ssd_graph.py\", line 144, in <module>\n","    tf.app.run(main)\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/platform/app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n","    _run_main(main, args)\n","  File \"usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n","    sys.exit(main(argv))\n","  File \"content/models/research/object_detection/export_tflite_ssd_graph.py\", line 140, in main\n","    FLAGS.max_classes_per_detection, use_regular_nms=FLAGS.use_regular_nms)\n","  File \"content/models/research/object_detection/export_tflite_ssd_graph_lib.py\", line 296, in export_tflite_graph\n","    saver = tf.train.Saver(**saver_kwargs)\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py\", line 828, in __init__\n","    self.build()\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py\", line 840, in build\n","    self._build(self._filename, build_save=True, build_restore=True)\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py\", line 878, in _build\n","    build_restore=build_restore)\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py\", line 508, in _build_internal\n","    restore_sequentially, reshape)\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py\", line 328, in _AddRestoreOps\n","    restore_sequentially)\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py\", line 575, in bulk_restore\n","    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/gen_io_ops.py\", line 1696, in restore_v2\n","    name=name)\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n","    op_def=op_def)\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n","    return func(*args, **kwargs)\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n","    attrs, op_def, compute_device)\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n","    op_def=op_def)\n","  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n","    self._traceback = tf_stack.extract_stack()\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uTikaJKpK6No","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":801},"executionInfo":{"status":"ok","timestamp":1594562920129,"user_tz":-120,"elapsed":132681,"user":{"displayName":"Clément Nicolas Graffard","photoUrl":"https://lh6.googleusercontent.com/-NkV18IrPyAg/AAAAAAAAAAI/AAAAAAAAH4E/7zBQvWoa2og/s64/photo.jpg","userId":"04495214703013170771"}},"outputId":"d527cb9d-2183-40f9-859e-e3e1c439852d"},"source":["!echo \"CONVERTING frozen graph to quantized TF Lite file...\"\n","!tflite_convert \\\n","  --output_file='{output_directory}/road_signs_quantized.tflite' \\\n","  --graph_def_file='{output_directory}/tflite_graph.pb' \\\n","  --inference_type=QUANTIZED_UINT8 \\\n","  --input_arrays='normalized_input_image_tensor' \\\n","  --output_arrays='TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3' \\\n","  --mean_values=128 \\\n","  --std_dev_values=128 \\\n","  --input_shapes=1,300,300,3 \\\n","  --change_concat_input_ranges=false \\\n","  --allow_nudging_weights_to_use_fast_gemm_kernel=true \\\n","  --allow_custom_ops"],"execution_count":26,"outputs":[{"output_type":"stream","text":["CONVERTING frozen graph to quantized TF Lite file...\n","2020-07-12 14:08:34.329059: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-07-12 14:08:34.346809: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:34.347559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n","pciBusID: 0000:00:04.0\n","2020-07-12 14:08:34.347875: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-07-12 14:08:34.349971: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-07-12 14:08:34.352204: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-07-12 14:08:34.352600: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-07-12 14:08:34.354708: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-07-12 14:08:34.356029: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-07-12 14:08:34.360201: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-07-12 14:08:34.360356: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:34.361126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:34.362018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-07-12 14:08:34.367785: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n","2020-07-12 14:08:34.368010: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1704bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-07-12 14:08:34.368077: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-07-12 14:08:34.421843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:34.422660: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1704d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-07-12 14:08:34.422707: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n","2020-07-12 14:08:34.422999: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:34.423713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n","pciBusID: 0000:00:04.0\n","2020-07-12 14:08:34.423804: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-07-12 14:08:34.423841: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-07-12 14:08:34.423881: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-07-12 14:08:34.423915: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-07-12 14:08:34.423949: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-07-12 14:08:34.423984: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-07-12 14:08:34.424019: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-07-12 14:08:34.424129: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:34.424916: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:34.425672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-07-12 14:08:34.425763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-07-12 14:08:34.427130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-07-12 14:08:34.427161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-07-12 14:08:34.427177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-07-12 14:08:34.427320: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:34.428100: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:34.428799: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-07-12 14:08:34.428860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RsZi5SHSSVur","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":801},"executionInfo":{"status":"ok","timestamp":1594562934048,"user_tz":-120,"elapsed":146590,"user":{"displayName":"Clément Nicolas Graffard","photoUrl":"https://lh6.googleusercontent.com/-NkV18IrPyAg/AAAAAAAAAAI/AAAAAAAAH4E/7zBQvWoa2og/s64/photo.jpg","userId":"04495214703013170771"}},"outputId":"695fbe3b-eaa7-4c29-f84c-4f79cf96e2e2"},"source":["!echo \"CONVERTING frozen graph to unquantized TF Lite file...\"\n","!tflite_convert \\\n","  --output_file='{output_directory}/road_signs_float.tflite' \\\n","  --graph_def_file='{output_directory}/tflite_graph.pb' \\\n","  --input_arrays='normalized_input_image_tensor' \\\n","  --output_arrays='TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3' \\\n","  --mean_values=128 \\\n","  --std_dev_values=128 \\\n","  --input_shapes=1,300,300,3 \\\n","  --change_concat_input_ranges=false \\\n","  --allow_nudging_weights_to_use_fast_gemm_kernel=true \\\n","  --allow_custom_ops \n"],"execution_count":27,"outputs":[{"output_type":"stream","text":["CONVERTING frozen graph to unquantized TF Lite file...\n","2020-07-12 14:08:46.310619: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-07-12 14:08:46.328663: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:46.329449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n","pciBusID: 0000:00:04.0\n","2020-07-12 14:08:46.329810: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-07-12 14:08:46.331673: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-07-12 14:08:46.333433: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-07-12 14:08:46.333847: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-07-12 14:08:46.335748: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-07-12 14:08:46.336855: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-07-12 14:08:46.340628: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-07-12 14:08:46.340787: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:46.341658: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:46.342496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-07-12 14:08:46.351642: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n","2020-07-12 14:08:46.351907: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x322cbc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-07-12 14:08:46.351975: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-07-12 14:08:46.409153: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:46.410030: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x322cd80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-07-12 14:08:46.410064: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n","2020-07-12 14:08:46.410247: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:46.411121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n","pciBusID: 0000:00:04.0\n","2020-07-12 14:08:46.411209: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-07-12 14:08:46.411281: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-07-12 14:08:46.411321: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-07-12 14:08:46.411359: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-07-12 14:08:46.411391: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-07-12 14:08:46.411424: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-07-12 14:08:46.411458: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-07-12 14:08:46.411587: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:46.412363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:46.413071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-07-12 14:08:46.413135: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-07-12 14:08:46.414530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-07-12 14:08:46.414563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-07-12 14:08:46.414591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-07-12 14:08:46.414788: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:46.415561: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-07-12 14:08:46.416278: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-07-12 14:08:46.416330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"usgBZvkz0nqD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":260},"executionInfo":{"status":"ok","timestamp":1594562941134,"user_tz":-120,"elapsed":153666,"user":{"displayName":"Clément Nicolas Graffard","photoUrl":"https://lh6.googleusercontent.com/-NkV18IrPyAg/AAAAAAAAAAI/AAAAAAAAH4E/7zBQvWoa2og/s64/photo.jpg","userId":"04495214703013170771"}},"outputId":"88bf352a-b4c5-46db-e436-b27e84e1c50d"},"source":["print(output_directory)\n","!ls -ltra '{output_directory}'\n","#pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\") # this is main one\n","pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")  # this is tflite graph\n","!cp '{label_map_pbtxt_fname}' '{output_directory}'"],"execution_count":28,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/Colab Notebooks/TransferLearning/Training/fine_tuned_model\n","total 134948\n","-rw------- 1 root root  2226422 Jul 12 13:33 model.ckpt.meta\n","-rw------- 1 root root    23543 Jul 12 13:33 model.ckpt.index\n","-rw------- 1 root root 18922628 Jul 12 13:33 model.ckpt.data-00000-of-00001\n","-rw------- 1 root root       77 Jul 12 13:33 checkpoint\n","-rw------- 1 root root 19817410 Jul 12 13:33 frozen_inference_graph.pb\n","drwx------ 3 root root     4096 Jul 12 13:33 saved_model\n","-rw------- 1 root root     4295 Jul 12 13:33 pipeline.config\n","-rw------- 1 root root 54190960 Jul 12 13:33 tflite_graph.pbtxt\n","-rw------- 1 root root 19408134 Jul 12 13:33 tflite_graph.pb\n","-rw------- 1 root root      275 Jul 12 14:04 label_map.pbtxt\n","-rw------- 1 root root  4793376 Jul 12 14:08 road_signs_quantized.tflite\n","-rw------- 1 root root 18792316 Jul 12 14:08 road_signs_float.tflite\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mz1gX19GlVW7","colab_type":"text"},"source":["## Run inference test\n","Test with images in repository `object_detection/data/images/test` directory."]},{"cell_type":"code","metadata":{"id":"Pzj9A4e5mj5l","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"status":"ok","timestamp":1594562941136,"user_tz":-120,"elapsed":153659,"user":{"displayName":"Clément Nicolas Graffard","photoUrl":"https://lh6.googleusercontent.com/-NkV18IrPyAg/AAAAAAAAAAI/AAAAAAAAH4E/7zBQvWoa2og/s64/photo.jpg","userId":"04495214703013170771"}},"outputId":"8aa4c237-4b08-4edd-ed58-4ed9bbb3b6a8"},"source":["import os\n","import glob\n","\n","# Path to frozen detection graph. This is the actual model that is used for the object detection.\n","PATH_TO_CKPT = pb_fname\n","print(PATH_TO_CKPT)\n","\n","# List of the strings that is used to add correct label for each box.\n","PATH_TO_LABELS = label_map_pbtxt_fname\n","\n","# If you want to test the code with your images, just add images files to the PATH_TO_TEST_IMAGES_DIR.\n","PATH_TO_TEST_IMAGES_DIR =  os.path.join(repo_dir_path, \"models/object_detection/data/images/test\")\n","\n","assert os.path.isfile(pb_fname)\n","assert os.path.isfile(PATH_TO_LABELS)\n","TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.jpg\"))\n","assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n","print(TEST_IMAGE_PATHS)"],"execution_count":29,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/Colab Notebooks/TransferLearning/Training/fine_tuned_model/frozen_inference_graph.pb\n","['/content/DeepPiCar/models/object_detection/data/images/test/2019-04-16-101426.jpg', '/content/DeepPiCar/models/object_detection/data/images/test/2019-04-16-095558.jpg', '/content/DeepPiCar/models/object_detection/data/images/test/2019-04-16-100317.jpg', '/content/DeepPiCar/models/object_detection/data/images/test/2019-04-16-101240.jpg', '/content/DeepPiCar/models/object_detection/data/images/test/2019-04-16-100738.jpg']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CG5YUMdg1Po7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594562942208,"user_tz":-120,"elapsed":154722,"user":{"displayName":"Clément Nicolas Graffard","photoUrl":"https://lh6.googleusercontent.com/-NkV18IrPyAg/AAAAAAAAAAI/AAAAAAAAH4E/7zBQvWoa2og/s64/photo.jpg","userId":"04495214703013170771"}},"outputId":"9c6f5a48-a1c0-435d-be95-5a2d20cf6327"},"source":["%cd /content/models/research/object_detection\n","\n","import numpy as np\n","import os\n","import six.moves.urllib as urllib\n","import sys\n","import tarfile\n","import tensorflow as tf\n","import zipfile\n","\n","from collections import defaultdict\n","from io import StringIO\n","from matplotlib import pyplot as plt\n","from PIL import Image\n","\n","# This is needed since the notebook is stored in the object_detection folder.\n","sys.path.append(\"..\")\n","from object_detection.utils import ops as utils_ops\n","\n","\n","# This is needed to display the images.\n","%matplotlib inline\n","\n","\n","from object_detection.utils import label_map_util\n","\n","from object_detection.utils import visualization_utils as vis_util\n","\n","\n","detection_graph = tf.Graph()\n","with detection_graph.as_default():\n","    od_graph_def = tf.GraphDef()\n","    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n","        serialized_graph = fid.read()\n","        od_graph_def.ParseFromString(serialized_graph)\n","        tf.import_graph_def(od_graph_def, name='')\n","\n","\n","label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n","categories = label_map_util.convert_label_map_to_categories(\n","    label_map, max_num_classes=num_classes, use_display_name=True)\n","category_index = label_map_util.create_category_index(categories)\n","\n","\n","def load_image_into_numpy_array(image):\n","    (im_width, im_height) = image.size\n","    return np.array(image.getdata()).reshape(\n","        (im_height, im_width, 3)).astype(np.uint8)\n","\n","# Size, in inches, of the output images.\n","IMAGE_SIZE = (12, 8)\n","\n","\n","def run_inference_for_single_image(image, graph):\n","    with graph.as_default():\n","        with tf.Session() as sess:\n","            # Get handles to input and output tensors\n","            ops = tf.get_default_graph().get_operations()\n","            all_tensor_names = {\n","                output.name for op in ops for output in op.outputs}\n","            tensor_dict = {}\n","            for key in [\n","                'num_detections', 'detection_boxes', 'detection_scores',\n","                'detection_classes', 'detection_masks'\n","            ]:\n","                tensor_name = key + ':0'\n","                if tensor_name in all_tensor_names:\n","                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n","                        tensor_name)\n","            if 'detection_masks' in tensor_dict:\n","                # The following processing is only for single image\n","                detection_boxes = tf.squeeze(\n","                    tensor_dict['detection_boxes'], [0])\n","                detection_masks = tf.squeeze(\n","                    tensor_dict['detection_masks'], [0])\n","                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n","                real_num_detection = tf.cast(\n","                    tensor_dict['num_detections'][0], tf.int32)\n","                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n","                                           real_num_detection, -1])\n","                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n","                                           real_num_detection, -1, -1])\n","                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n","                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n","                detection_masks_reframed = tf.cast(\n","                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n","                # Follow the convention by adding back the batch dimension\n","                tensor_dict['detection_masks'] = tf.expand_dims(\n","                    detection_masks_reframed, 0)\n","            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n","\n","            # Run inference\n","            output_dict = sess.run(tensor_dict,\n","                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n","\n","            # all outputs are float32 numpy arrays, so convert types as appropriate\n","            output_dict['num_detections'] = int(\n","                output_dict['num_detections'][0])\n","            output_dict['detection_classes'] = output_dict[\n","                'detection_classes'][0].astype(np.uint8)\n","            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n","            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n","            if 'detection_masks' in output_dict:\n","                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n","    return output_dict\n","\n"],"execution_count":30,"outputs":[{"output_type":"stream","text":["/content/models/research/object_detection\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HEmFi1DFGBQ8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1vQtAOjwejDq3NnWNGhu-2opbOLhnJRKx"},"executionInfo":{"status":"ok","timestamp":1594564586918,"user_tz":-120,"elapsed":22417,"user":{"displayName":"Clément Nicolas Graffard","photoUrl":"https://lh6.googleusercontent.com/-NkV18IrPyAg/AAAAAAAAAAI/AAAAAAAAH4E/7zBQvWoa2og/s64/photo.jpg","userId":"04495214703013170771"}},"outputId":"f6b2257a-dad0-400f-d89b-99c465c03919"},"source":["# running inferences.  This should show images with bounding boxes\n","%matplotlib inline\n","\n","print('Running inferences on %s' % TEST_IMAGE_PATHS)\n","for image_path in TEST_IMAGE_PATHS:\n","    image = Image.open(image_path)\n","    # the array based representation of the image will be used later in order to prepare the\n","    # result image with boxes and labels on it.\n","    image_np = load_image_into_numpy_array(image)\n","    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n","    image_np_expanded = np.expand_dims(image_np, axis=0)\n","    # Actual detection.\n","    output_dict = run_inference_for_single_image(image_np, detection_graph)\n","    # Visualization of the results of a detection.\n","    vis_util.visualize_boxes_and_labels_on_image_array(\n","        image_np,\n","        output_dict['detection_boxes'],\n","        output_dict['detection_classes'],\n","        output_dict['detection_scores'],\n","        category_index,\n","        instance_masks=output_dict.get('detection_masks'),\n","        use_normalized_coordinates=True,\n","        line_thickness=2)\n","    plt.figure(figsize=IMAGE_SIZE)\n","    plt.imshow(image_np)\n","\n"],"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"1HhQ9y_Jcrfa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1594562968249,"user_tz":-120,"elapsed":180741,"user":{"displayName":"Clément Nicolas Graffard","photoUrl":"https://lh6.googleusercontent.com/-NkV18IrPyAg/AAAAAAAAAAI/AAAAAAAAH4E/7zBQvWoa2og/s64/photo.jpg","userId":"04495214703013170771"}},"outputId":"085558a5-bc5a-4bf4-cd8d-9c566316ff28"},"source":["# download this file from google drive.\n","!ls -lt '/content/gdrive/My Drive/Colab Notebooks/TransferLearning/Training/fine_tuned_model/road_signs_quantized.tflite'"],"execution_count":32,"outputs":[{"output_type":"stream","text":["-rw------- 1 root root 4793376 Jul 12 14:08 '/content/gdrive/My Drive/Colab Notebooks/TransferLearning/Training/fine_tuned_model/road_signs_quantized.tflite'\n"],"name":"stdout"}]}]}